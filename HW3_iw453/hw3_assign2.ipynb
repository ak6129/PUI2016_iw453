{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUI 2016 HOMEWORK 3, ASSIGNMENT 2\n",
    "#### Ian Wright, iw453\n",
    "#### September 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib, json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDEA:\n",
    "\n",
    "There is demand for expanded citibike service in Upper Manhattan / Harlem / Columbia University.\n",
    "\n",
    "#### HYPOTHESIS:\n",
    "\n",
    "$H_0:$ The average daily rides (normalized per bike) that *start* along the north edge of the Citibike service zone in Manhattan (all Citibike stations on, or above, 106 St.) is *less than or equal to* that of Citibike stations in a similar, but non-boundary, region of Manhattan (between 91 St and 106 St). Timeframe set as a most recent complete 4 weeks.\n",
    "\n",
    "##### H_0: avg(rides /bike /day)_(north of 106st, manhattan) <= avg(rides /bike /day)_(south of 106st, manhattan)\n",
    "\n",
    "$H_1:$ The average daily rides (normalized per bike) that *start* along the north edge of the Citibike service zone in Manhattan (all Citibike stations on, or above, 106 St.) is *greater than* that of Citibike stations in a similar, but non-boundary, region of Manhattan (between 91 St and 106 St). Timeframe set as a most recent complete 4 weeks.\n",
    "\n",
    "##### H_1: avg(rides /bike /day)_(north of 106st, manhattan) > avg(rides /bike /day)_(south of 106st, manhattan)\n",
    "\n",
    "#### SIGNIFICANCE LEVEL:\n",
    "\n",
    "For this test, I'll use a significance level of $\\alpha=0.05$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA STRATEGY:\n",
    "\n",
    "Citibike provides a json feed of all stations in the system. We'll parse through this to build a list of station IDs, names, and total bike capacity for each.\n",
    "\n",
    "Then we'll cross-reference a citibike map for the relevant stations for our study, and group our dataset into boundary and non-boundary stations (and drop unneeded stations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get station data from citibike station feed\n",
    "url = \"https://feeds.citibikenyc.com/stations/stations.json\"\n",
    "response = urllib.urlopen(url)\n",
    "stations = json.loads(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use list comprehension to build a master list of relevant station data\n",
    "station_data = [{'id':station['id'],\n",
    "                 'stationName':station['stationName'],\n",
    "                 'totalDocks':station['totalDocks']} \n",
    "                for station in stations['stationBeanList']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, citibike doesn't provide a map with unique integer IDs for each station... instead, we need to inspect the map and collect a list of strings for stationNames in our boundary and non-boundary zones. Then we'll search the station_data list for those stationNames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of stationName for boundary zone: \n",
    "boundary_names = ['Cathedral Pkwy & Broadway', 'West End Ave & W 107 St', \n",
    "                  'W 106 St & Amsterdam Ave', 'W 107 St & Columbus Ave',\n",
    "                 'W 106 St & Central Park West', 'Central Park North & Adam Clayton Powell Blvd',\n",
    "                 'E 110 St & Madison Ave', 'E 106 St & Madison Ave', 'E 106 St & Lexington Ave',\n",
    "                 'E 109 St & 3 Ave', 'E 106 St & 1 Av']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of stationName for non-boundary zone: \n",
    "non_boundary_names = ['Riverside Dr & W 104 St', 'West End Ave & W 94 St', 'W 92 St & Broadway',\n",
    "                     'W 100 St & Broadway', 'W 95 St & Broadway', 'W 104 St & Amsterdam Ave',\n",
    "                     'Columbus Ave & W 95 St', 'Columbus Ave & W 103 St', 'W 100 St & Manhattan Ave',\n",
    "                     'Central Park W & W 96 St', 'Central Park West & W 100 St',\n",
    "                      'Central Park West & W 102 St', '5 Ave & E 93 St', '5 Ave & E 103 St',\n",
    "                      'E 97 St & Madison Ave', 'Madison Ave & E 99 St', 'E 91 St & Park Ave',\n",
    "                      'E 102 St & Park Ave','E 103 St & Lexington Ave', 'E 95 St & 3 Ave',\n",
    "                      'E 97 St & 3 Ave', '3 Ave & E 100 St', 'E 91 St & 2 Ave', '2 Ave & E 99 St',\n",
    "                      '2 Ave & E 104 St', '1 Ave & E 94 St', 'E 102 St & 1 Ave']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be computationally slow, but we need to iterate through all station data to pick out those stations that belong in a boundary or non-boundary group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boundary_stations = []\n",
    "non_boundary_stations = []\n",
    "for station in station_data:\n",
    "    if station['stationName'] in boundary_names:\n",
    "        boundary_stations.append(station)\n",
    "    elif station['stationName'] in non_boundary_names:\n",
    "        non_boundary_stations.append(station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now that the lists are built, we'll be using integer IDs to identify the stations\n",
    "# we can drop all the station names to simplify things\n",
    "boundary_stations = [{'id':station['id'],\n",
    "                      'totalDocks':station['totalDocks']}\n",
    "                     for station in boundary_stations]\n",
    "\n",
    "non_boundary_stations = [{'id':station['id'],\n",
    "                      'totalDocks':station['totalDocks']}\n",
    "                     for station in non_boundary_stations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 3323, 'totalDocks': 59},\n",
       " {'id': 3343, 'totalDocks': 23},\n",
       " {'id': 3357, 'totalDocks': 35},\n",
       " {'id': 3366, 'totalDocks': 19},\n",
       " {'id': 3374, 'totalDocks': 36},\n",
       " {'id': 3383, 'totalDocks': 25},\n",
       " {'id': 3387, 'totalDocks': 25},\n",
       " {'id': 3390, 'totalDocks': 24},\n",
       " {'id': 3400, 'totalDocks': 24},\n",
       " {'id': 3424, 'totalDocks': 27}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 3292, 'totalDocks': 43},\n",
       " {'id': 3293, 'totalDocks': 24},\n",
       " {'id': 3294, 'totalDocks': 35},\n",
       " {'id': 3295, 'totalDocks': 59},\n",
       " {'id': 3301, 'totalDocks': 39},\n",
       " {'id': 3302, 'totalDocks': 23},\n",
       " {'id': 3305, 'totalDocks': 39},\n",
       " {'id': 3307, 'totalDocks': 31},\n",
       " {'id': 3309, 'totalDocks': 30},\n",
       " {'id': 3312, 'totalDocks': 39},\n",
       " {'id': 3314, 'totalDocks': 32},\n",
       " {'id': 3316, 'totalDocks': 47},\n",
       " {'id': 3320, 'totalDocks': 31},\n",
       " {'id': 3325, 'totalDocks': 31},\n",
       " {'id': 3327, 'totalDocks': 27},\n",
       " {'id': 3328, 'totalDocks': 39},\n",
       " {'id': 3331, 'totalDocks': 39},\n",
       " {'id': 3336, 'totalDocks': 41},\n",
       " {'id': 3338, 'totalDocks': 31},\n",
       " {'id': 3341, 'totalDocks': 59},\n",
       " {'id': 3345, 'totalDocks': 35},\n",
       " {'id': 3350, 'totalDocks': 39},\n",
       " {'id': 3351, 'totalDocks': 25},\n",
       " {'id': 3363, 'totalDocks': 33},\n",
       " {'id': 3367, 'totalDocks': 35},\n",
       " {'id': 3379, 'totalDocks': 35}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_boundary_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to load some actual trip data from citibike to use as our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the citibike trip data for the last available month.\n",
    "# At the time of this writing (9/24/2016) that is June 2016.\n",
    "!curl -O 'https://s3.amazonaws.com/tripdata/201606-citibike-tripdata.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import trip data into a pandas dataframe\n",
    "# ⚠️ WARNING ⚠️: This import will take a long time. Seriously, like 5-10 minutes.\n",
    "# This is because of the datetime conversation.\n",
    "trips = pd.read_csv('201606-citibike-tripdata.zip',\n",
    "                    dtype={'starttime': 'str',\n",
    "                           'start station id': 'int64'},\n",
    "                    parse_dates=['starttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all columns except for starttime and start station id\n",
    "trips = trips[[\"starttime\", \"start station id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>start station id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109067</th>\n",
       "      <td>2016-06-03 00:00:12</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109068</th>\n",
       "      <td>2016-06-03 00:00:37</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109069</th>\n",
       "      <td>2016-06-03 00:00:36</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 starttime  start station id\n",
       "109067 2016-06-03 00:00:12               164\n",
       "109068 2016-06-03 00:00:37               264\n",
       "109069 2016-06-03 00:00:36               368"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the data\n",
    "trips.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert starttime to datetime datatype in a new column\n",
    "# WARNING: Processor intensive, will take some time\n",
    "# trips.loc[:, 'start_datetime'] = pd.to_datetime(trips.starttime, format='%-m/%-d/%Y %H:%M:%S').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter to only 4 weeks of data to represent only 4 instances of every day of the week (4 Mondays, 4 Tuesdays, etc). \n",
    "# The last day of June 2016 was Thursday the 30th. Thus, this dataset now captures all rides from Thursday the 3rd at\n",
    "# midnight to Thursday the 30th at 23:59:59.\n",
    "trips = trips[trips[\"starttime\"] > \"2016-06-03 00:00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>start station id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109263</th>\n",
       "      <td>2016-06-03 00:18:51</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109315</th>\n",
       "      <td>2016-06-03 00:26:03</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110368</th>\n",
       "      <td>2016-06-03 06:02:27</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110572</th>\n",
       "      <td>2016-06-03 06:18:04</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110599</th>\n",
       "      <td>2016-06-03 06:19:47</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111182</th>\n",
       "      <td>2016-06-03 06:48:23</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111672</th>\n",
       "      <td>2016-06-03 07:06:25</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112299</th>\n",
       "      <td>2016-06-03 07:32:30</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112694</th>\n",
       "      <td>2016-06-03 07:45:24</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112771</th>\n",
       "      <td>2016-06-03 07:47:20</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112773</th>\n",
       "      <td>2016-06-03 07:47:22</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113065</th>\n",
       "      <td>2016-06-03 07:54:29</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113454</th>\n",
       "      <td>2016-06-03 08:04:08</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113571</th>\n",
       "      <td>2016-06-03 08:06:48</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113981</th>\n",
       "      <td>2016-06-03 08:17:58</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114666</th>\n",
       "      <td>2016-06-03 08:41:56</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114713</th>\n",
       "      <td>2016-06-03 08:43:45</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115042</th>\n",
       "      <td>2016-06-03 08:53:26</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115103</th>\n",
       "      <td>2016-06-03 08:55:49</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115269</th>\n",
       "      <td>2016-06-03 09:01:05</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115509</th>\n",
       "      <td>2016-06-03 09:09:44</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115632</th>\n",
       "      <td>2016-06-03 09:13:35</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115778</th>\n",
       "      <td>2016-06-03 09:18:40</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115958</th>\n",
       "      <td>2016-06-03 09:24:38</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115967</th>\n",
       "      <td>2016-06-03 09:24:51</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116201</th>\n",
       "      <td>2016-06-03 09:35:49</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116356</th>\n",
       "      <td>2016-06-03 09:41:08</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116515</th>\n",
       "      <td>2016-06-03 09:48:19</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116584</th>\n",
       "      <td>2016-06-03 09:50:43</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116586</th>\n",
       "      <td>2016-06-03 09:50:47</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451361</th>\n",
       "      <td>2016-06-30 19:30:09</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451389</th>\n",
       "      <td>2016-06-30 19:30:29</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451574</th>\n",
       "      <td>2016-06-30 19:33:21</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451596</th>\n",
       "      <td>2016-06-30 19:33:50</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451598</th>\n",
       "      <td>2016-06-30 19:33:52</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451683</th>\n",
       "      <td>2016-06-30 19:34:55</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452466</th>\n",
       "      <td>2016-06-30 19:46:52</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452474</th>\n",
       "      <td>2016-06-30 19:47:02</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452497</th>\n",
       "      <td>2016-06-30 19:47:21</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452503</th>\n",
       "      <td>2016-06-30 19:47:31</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452543</th>\n",
       "      <td>2016-06-30 19:48:09</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452764</th>\n",
       "      <td>2016-06-30 19:52:10</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452815</th>\n",
       "      <td>2016-06-30 19:52:57</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452901</th>\n",
       "      <td>2016-06-30 19:54:21</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453339</th>\n",
       "      <td>2016-06-30 20:01:56</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453615</th>\n",
       "      <td>2016-06-30 20:06:45</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453670</th>\n",
       "      <td>2016-06-30 20:07:50</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453960</th>\n",
       "      <td>2016-06-30 20:13:32</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454001</th>\n",
       "      <td>2016-06-30 20:14:18</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454491</th>\n",
       "      <td>2016-06-30 20:22:55</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454692</th>\n",
       "      <td>2016-06-30 20:26:58</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455097</th>\n",
       "      <td>2016-06-30 20:36:02</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455573</th>\n",
       "      <td>2016-06-30 20:47:24</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456203</th>\n",
       "      <td>2016-06-30 21:04:53</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456272</th>\n",
       "      <td>2016-06-30 21:06:33</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456881</th>\n",
       "      <td>2016-06-30 21:24:49</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457367</th>\n",
       "      <td>2016-06-30 21:41:12</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458585</th>\n",
       "      <td>2016-06-30 22:29:17</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458586</th>\n",
       "      <td>2016-06-30 22:29:18</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460300</th>\n",
       "      <td>2016-06-30 23:59:09</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7066 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  starttime  start station id\n",
       "109263  2016-06-03 00:18:51               168\n",
       "109315  2016-06-03 00:26:03               168\n",
       "110368  2016-06-03 06:02:27               168\n",
       "110572  2016-06-03 06:18:04               168\n",
       "110599  2016-06-03 06:19:47               168\n",
       "111182  2016-06-03 06:48:23               168\n",
       "111672  2016-06-03 07:06:25               168\n",
       "112299  2016-06-03 07:32:30               168\n",
       "112694  2016-06-03 07:45:24               168\n",
       "112771  2016-06-03 07:47:20               168\n",
       "112773  2016-06-03 07:47:22               168\n",
       "113065  2016-06-03 07:54:29               168\n",
       "113454  2016-06-03 08:04:08               168\n",
       "113571  2016-06-03 08:06:48               168\n",
       "113981  2016-06-03 08:17:58               168\n",
       "114666  2016-06-03 08:41:56               168\n",
       "114713  2016-06-03 08:43:45               168\n",
       "115042  2016-06-03 08:53:26               168\n",
       "115103  2016-06-03 08:55:49               168\n",
       "115269  2016-06-03 09:01:05               168\n",
       "115509  2016-06-03 09:09:44               168\n",
       "115632  2016-06-03 09:13:35               168\n",
       "115778  2016-06-03 09:18:40               168\n",
       "115958  2016-06-03 09:24:38               168\n",
       "115967  2016-06-03 09:24:51               168\n",
       "116201  2016-06-03 09:35:49               168\n",
       "116356  2016-06-03 09:41:08               168\n",
       "116515  2016-06-03 09:48:19               168\n",
       "116584  2016-06-03 09:50:43               168\n",
       "116586  2016-06-03 09:50:47               168\n",
       "...                     ...               ...\n",
       "1451361 2016-06-30 19:30:09               168\n",
       "1451389 2016-06-30 19:30:29               168\n",
       "1451574 2016-06-30 19:33:21               168\n",
       "1451596 2016-06-30 19:33:50               168\n",
       "1451598 2016-06-30 19:33:52               168\n",
       "1451683 2016-06-30 19:34:55               168\n",
       "1452466 2016-06-30 19:46:52               168\n",
       "1452474 2016-06-30 19:47:02               168\n",
       "1452497 2016-06-30 19:47:21               168\n",
       "1452503 2016-06-30 19:47:31               168\n",
       "1452543 2016-06-30 19:48:09               168\n",
       "1452764 2016-06-30 19:52:10               168\n",
       "1452815 2016-06-30 19:52:57               168\n",
       "1452901 2016-06-30 19:54:21               168\n",
       "1453339 2016-06-30 20:01:56               168\n",
       "1453615 2016-06-30 20:06:45               168\n",
       "1453670 2016-06-30 20:07:50               168\n",
       "1453960 2016-06-30 20:13:32               168\n",
       "1454001 2016-06-30 20:14:18               168\n",
       "1454491 2016-06-30 20:22:55               168\n",
       "1454692 2016-06-30 20:26:58               168\n",
       "1455097 2016-06-30 20:36:02               168\n",
       "1455573 2016-06-30 20:47:24               168\n",
       "1456203 2016-06-30 21:04:53               168\n",
       "1456272 2016-06-30 21:06:33               168\n",
       "1456881 2016-06-30 21:24:49               168\n",
       "1457367 2016-06-30 21:41:12               168\n",
       "1458585 2016-06-30 22:29:17               168\n",
       "1458586 2016-06-30 22:29:18               168\n",
       "1460300 2016-06-30 23:59:09               168\n",
       "\n",
       "[7066 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips[trips[\"start station id\"].isin([168])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get relevant trips \n",
    "boundary_trips = trips[trips[\"start station id\"].isin(map(lambda x: x[\"id\"], boundary_stations))]\n",
    "non_boundary_trips = trips[trips[\"start station id\"].isin(map(lambda x: x[\"id\"], non_boundary_stations))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starttime</th>\n",
       "      <th>start station id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [starttime, start station id]\n",
       "Index: []"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_boundary_trips"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
